# -*- coding: utf-8 -*-
"""DEEP_Learning_Project_4NC6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LHbnjK_XgKvVpbAdPxbXngn3W4XTE_HI

# Soil Spectroscopy — Full pipeline (Base, Transfer, Hybrid)

**What this notebook contains:**

- Preprocessing (drop PIDN, remove CO₂ band, spectral transforms)
- Base models: PLS / LightGBM
- Transfer model: Autoencoder pretraining → encoder fine-tune
- Hybrid model: Conv1D + tabular fusion
- 5-fold CV, OOF stacking, MCRMSE evaluation, plots

**How to use:** Upload `train.csv` and `test.csv` in the notebook environment (Colab: left pane Upload; Kaggle: use `/kaggle/input/...`).
"""

print("If running in Colab, ensure packages are installed. On Kaggle skip this step.")

import os, math, random, gc, json
import numpy as np, pandas as pd
from sklearn.model_selection import KFold, train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.cross_decomposition import PLSRegression
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score
import lightgbm as lgb
import matplotlib.pyplot as plt
from scipy.signal import savgol_filter
import tensorflow as tf
from tensorflow.keras import layers, models, backend as K
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
print('Imports done. TensorFlow version:', tf.__version__)

"""## 1) Load data

Place `train.csv` and `test.csv` in the working directory. If using Kaggle, set paths to the input dataset. If using Colab, upload files to the left pane.

"""

TRAIN_CSV = 'training.csv'
TEST_CSV  = 'sorted_test.csv'


if not os.path.exists(TRAIN_CSV) and os.path.exists('/kaggle/input/'):

    for root, dirs, files in os.walk('/kaggle/input'):
        for f in files:
            if f.lower().startswith('train') and f.lower().endswith('.csv'):
                TRAIN_CSV = os.path.join(root, f)
            if f.lower().startswith('test') and f.lower().endswith('.csv'):
                TEST_CSV = os.path.join(root, f)

print('TRAIN_CSV=', TRAIN_CSV)
print('TEST_CSV=', TEST_CSV)

train = pd.read_csv(TRAIN_CSV)
print('Loaded train shape:', train.shape)
train.head(3)

# Define columns and clean
TARGETS = ['SOC','pH','Ca','P','Sand']
ID_COLS = ['PIDN']

spec_cols = [c for c in train.columns if c.startswith('m')]
print('Total spectral cols:', len(spec_cols))

# Remove CO2 band columns between 2352.76 and 2379.76 cm^-1
def mval(c):
    try:
        return float(c[1:])
    except:
        return None

co2_min, co2_max = 2352.76, 2379.76
co2_cols = [c for c in spec_cols if (mval(c) is not None and co2_min <= mval(c) <= co2_max)]
print('CO2 cols count:', len(co2_cols))
spec_cols_clean = [c for c in spec_cols if c not in co2_cols]
print('Spectral cols after CO2 removal:', len(spec_cols_clean))

# Tabular cols (everything not spectral, not target, not id)
tab_cols = [c for c in train.columns if c not in spec_cols + TARGETS + ID_COLS]
print('Tabular cols:', tab_cols)

# Preprocessing helpers: SG smoothing, SNV, PCA helper
from scipy.signal import savgol_filter

def apply_savgol(X, window=11, poly=2, deriv=0):
    # X: (n_samples, n_timesteps)
    return savgol_filter(X, window_length=window, polyorder=poly, deriv=deriv, axis=1, mode='mirror')

def snv(X):
    # Standard Normal Variate per sample
    mu = X.mean(axis=1, keepdims=True)
    sigma = X.std(axis=1, keepdims=True)
    return (X - mu) / (sigma + 1e-12)

def mcrmse(y_true, y_pred):
    se = ((y_true - y_pred)**2).mean(axis=0)
    rmse = np.sqrt(se)
    return float(rmse.mean()), rmse

print('Helpers ready')

# Prepare arrays
# Drop PIDN if exists
if 'PIDN' in train.columns:
    train = train.drop(columns=['PIDN'])

X_spec = train[spec_cols_clean].values.astype(np.float32)
X_tab  = train[tab_cols].copy()
if 'Depth' in X_tab.columns:
    X_tab['Depth_enc'] = LabelEncoder().fit_transform(X_tab['Depth'])
    X_tab = X_tab.drop(columns=['Depth'])

X_tab = X_tab.values.astype(np.float32)
y = train[TARGETS].values.astype(np.float32)

print('Shapes: X_spec, X_tab, y ->', X_spec.shape, X_tab.shape, y.shape)

# Optional transforms: SG smoothing and SNV (toggle)
APPLY_SG = True
SG_WINDOW=11; SG_POLY=2; SG_DERIV=0
APPLY_SNV = False

if APPLY_SG:
    print('Applying Savitzky-Golay...')
    X_spec = apply_savgol(X_spec, window=SG_WINDOW, poly=SG_POLY, deriv=SG_DERIV)
if APPLY_SNV:
    print('Applying SNV...')
    X_spec = snv(X_spec)

# Scale spectral and tabular separately
spec_scaler = StandardScaler().fit(X_spec)
X_spec_s = spec_scaler.transform(X_spec)
tab_scaler  = StandardScaler().fit(X_tab)
X_tab_s = tab_scaler.transform(X_tab)

# For CNN input reshape
X_spec_cnn = X_spec_s[..., np.newaxis]  # shape (n, timesteps, 1)

print('Prepared: X_spec_s shape, X_tab_s shape ->', X_spec_s.shape, X_tab_s.shape)

import matplotlib.pyplot as plt
wavenums = [mval(c) for c in spec_cols_clean]
plt.figure(figsize=(10,4))
plt.plot(wavenums, X_spec_s.mean(axis=0))
plt.gca().invert_xaxis()
plt.title('Mean scaled spectrum (after preprocessing)')
plt.xlabel('Wavenumber (cm^-1)')
plt.show()

import os, math, random, gc, json
import numpy as np, pandas as pd
from sklearn.model_selection import KFold, train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.cross_decomposition import PLSRegression
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score
import lightgbm as lgb
import matplotlib.pyplot as plt
from scipy.signal import savgol_filter
import tensorflow as tf
from tensorflow.keras import layers, models, backend as K
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
print('Imports done. TensorFlow version:', tf.__version__)

# Base models: PLS (multioutput) and LightGBM on PCA features
NFOLDS = 5
kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=42)

# PCA for tree models
N_PCS = 60
pca = PCA(n_components=N_PCS, random_state=42).fit(X_spec_s)
X_pca = pca.transform(X_spec_s)
print('PCA explained variance sum:', pca.explained_variance_ratio_.sum())

# Combine features for tree models
spec_stats = np.vstack([X_spec_s.mean(axis=1), X_spec_s.std(axis=1)]).T
X_tree = np.hstack([X_pca, spec_stats, X_tab_s])

oof_pls = np.zeros_like(y); oof_lgb = np.zeros_like(y)
test_preds_lgb = None

for fold, (tr_idx, val_idx) in enumerate(kf.split(X_tree)):
    print('\nFold', fold+1)
    # PLS on spectra+tabular (simple baseline)
    pls = PLSRegression(n_components=30)
    pls.fit(np.hstack([X_spec_s[tr_idx], X_tab_s[tr_idx]]), y[tr_idx])
    oof_pls[val_idx] = pls.predict(np.hstack([X_spec_s[val_idx], X_tab_s[val_idx]]))
    # LightGBM per target
    for t_i, tname in enumerate(TARGETS):
        tr_X = X_tree[tr_idx]; tr_y = y[tr_idx, t_i]
        val_X = X_tree[val_idx]
        lgb_train = lgb.Dataset(tr_X, tr_y)
        lgb_val = lgb.Dataset(X_tree[val_idx], y[val_idx, t_i], reference=lgb_train)
        params = {'objective':'regression','metric':'rmse','verbosity':-1,
                  'learning_rate':0.05,'num_leaves':31,'seed':42,'feature_fraction':0.8,'bagging_fraction':0.8,'bagging_freq':5}
        callbacks = [lgb.early_stopping(100, verbose=100)] # Use lgb.early_stopping callback
        model = lgb.train(params, lgb_train, num_boost_round=2000, valid_sets=[lgb_val], callbacks=callbacks)
        oof_lgb[val_idx, t_i] = model.predict(val_X, num_iteration=model.best_iteration)

    gc.collect()

print('\nPLS OOF MCRMSE:', mcrmse(y, oof_pls)[0])
print('LGB OOF MCRMSE:', mcrmse(y, oof_lgb)[0])

def build_base_mlp(input_shape, n_targets):
    inp = layers.Input(shape=input_shape)
    x = layers.Flatten()(inp) # Flatten if input is 3D
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dense(64, activation='relu')(x)
    out = layers.Dense(n_targets, activation='linear')(x)
    model = models.Model(inp, out, name='Base_MLP')
    model.compile(optimizer='adam', loss='mse', metrics=[keras_mcrmse])
    return model

from tensorflow.keras.utils import plot_model
plot_model(model, to_file='hybrid_model_architecture.png', show_shapes=True, show_layer_names=True)

# Transfer model: simple autoencoder pretraining on spectra, then use encoder
tf.random.set_seed(42)
input_shape = X_spec_cnn.shape[1:]  # (timesteps, 1)

def build_autoencoder(input_shape, latent_dim=128):
    inp = layers.Input(shape=input_shape)
    x = layers.Conv1D(64, 5, padding='same', activation='relu')(inp)
    x = layers.MaxPooling1D(2, padding='same')(x)
    x = layers.Conv1D(128, 5, padding='same', activation='relu')(x)
    x = layers.MaxPooling1D(2, padding='same')(x)
    x = layers.Conv1D(256, 3, padding='same', activation='relu')(x)
    # Capture shape before GlobalAveragePooling1D
    x_before_global_avg_pooling = x
    x = layers.GlobalAveragePooling1D()(x)
    z = layers.Dense(latent_dim, activation='relu', name='latent')(x)

    # decoder to reconstruct the original input shape
    # Based on the encoder path: (N, 3563, 1) -> ... -> (N, 891, 256) -> GlobalAveragePooling -> (N, 256)
    # We need to reverse from latent_dim back to (N, 3563, 1)

    # First, map latent_dim back to the flattened representation before GlobalAveragePooling
    # Use the captured shape from x_before_global_avg_pooling
    timesteps_from_encoder = K.int_shape(x_before_global_avg_pooling)[1]
    features_from_encoder = K.int_shape(x_before_global_avg_pooling)[2]

    x2 = layers.Dense(timesteps_from_encoder * features_from_encoder, activation='relu')(z)
    x2 = layers.Reshape((timesteps_from_encoder, features_from_encoder))(x2) # Reshape back to (None, 891, 256)

    # Reverse the upsampling and convolution operations
    x2 = layers.UpSampling1D(2)(x2) # (None, 1782, 256)
    x2 = layers.Conv1D(128, 5, padding='same', activation='relu')(x2) # (None, 1782, 128)
    x2 = layers.UpSampling1D(2)(x2) # (None, 3564, 128) - Note: this is 3564, not 3563
    x2 = layers.Conv1D(64, 5, padding='same', activation='relu')(x2) # (None, 3564, 64)
    out = layers.Conv1D(1, 3, padding='same', activation='linear')(x2) # (None, 3564, 1)

    # Crop the output to exactly match the input sequence length (3563)
    output_length = input_shape[0] # 3563
    current_length = K.int_shape(out)[1] # 3564
    if current_length > output_length:
        # Crop from the end to match the original input length
        out = layers.Cropping1D(cropping=(0, current_length - output_length))(out)

    ae = models.Model(inp, out, name='autoencoder')
    ae.compile(optimizer='adam', loss='mse')
    return ae

print('Building autoencoder...')
ae = build_autoencoder(input_shape, latent_dim=128)
ae.summary()

# Pretrain autoencoder quickly (for demo; increase epochs in real runs)
es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)
ae.fit(X_spec_cnn, X_spec_cnn, epochs=10, batch_size=32, callbacks=[es], verbose=2)

# Extract encoder part
encoder = models.Model(ae.input, ae.get_layer('latent').output)
enc_feats = encoder.predict(X_spec_cnn)
print('Encoder features shape:', enc_feats.shape)

# Define a Keras-compatible MCRMSE metric that returns a single scalar tensor
def keras_mcrmse(y_true, y_pred):
    se = K.square(y_true - y_pred)
    rmse_per_output = K.sqrt(K.mean(se, axis=0))
    return K.mean(rmse_per_output)

# Fine-tune: build a small regressor on top of encoder + tabular
def build_transfer_regressor(encoder, tab_dim, n_targets):
    for layer in encoder.layers: layer.trainable = True  # allow fine-tuning
    spec_in = encoder.input
    spec_feat = encoder.output
    tab_in = layers.Input(shape=(tab_dim,))
    t = layers.Dense(64, activation='relu')(tab_in)
    merged = layers.concatenate([spec_feat, t])
    h = layers.Dense(128, activation='relu')(merged)
    out = layers.Dense(n_targets, activation='linear')(h)
    model = models.Model([spec_in, tab_in], out)
    model.compile(optimizer='adam', loss='mse', metrics=[keras_mcrmse])
    return model

transfer_model = build_transfer_regressor(encoder, X_tab_s.shape[1], len(TARGETS))
transfer_model.summary()

# Quick train (use CV for real training)
transfer_model.fit([X_spec_cnn, X_tab_s], y, epochs=20, batch_size=32, verbose=2)

# Hybrid Conv1D + tabular model with CV (simple demonstration)
def build_hybrid(spec_shape, tab_dim, dropout=0.2):
    spec_in = layers.Input(shape=spec_shape)
    x = layers.Conv1D(64, 5, padding='same', activation='relu')(spec_in)
    x = layers.BatchNormalization()(x)
    x = layers.Conv1D(128, 5, padding='same', activation='relu')(x)
    x = layers.GlobalAveragePooling1D()(x)
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dropout(dropout)(x)

    tab_in = layers.Input(shape=(tab_dim,))
    t = layers.Dense(64, activation='relu')(tab_in)
    t = layers.BatchNormalization()(t)
    t = layers.Dense(64, activation='relu')(t)

    merged = layers.concatenate([x,t])
    h = layers.Dense(128, activation='relu')(merged)
    out = layers.Dense(len(TARGETS), activation='linear')(h)
    model = models.Model([spec_in, tab_in], out)
    model.compile(optimizer='adam', loss='mse', metrics=[keras_mcrmse])
    return model

# 5-fold CV training for hybrid
oof_hybrid = np.zeros_like(y)
for fold, (tr_idx, val_idx) in enumerate(kf.split(X_spec_cnn)):
    print('\nHybrid Fold', fold+1)
    model = build_hybrid(X_spec_cnn.shape[1:], X_tab_s.shape[1], dropout=0.25)
    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    model.fit([X_spec_cnn[tr_idx], X_tab_s[tr_idx]], y[tr_idx],
              validation_data=([X_spec_cnn[val_idx], X_tab_s[val_idx]], y[val_idx]),
              epochs=80, batch_size=32, callbacks=[es], verbose=2)
    oof_hybrid[val_idx] = model.predict([X_spec_cnn[val_idx], X_tab_s[val_idx]])

print('Hybrid OOF MCRMSE:', mcrmse(y, oof_hybrid)[0])

# Simple stacking: use OOFs from PLS, LGB, and Hybrid (we have oof_pls, oof_lgb, oof_hybrid)
# Ensure shapes are correct
print('Shapes:', oof_pls.shape, oof_lgb.shape, oof_hybrid.shape)

stack_features = np.hstack([oof_pls, oof_lgb, oof_hybrid])
print('Stack features shape:', stack_features.shape)

# Train meta-learner (Ridge multioutput)
meta = Ridge(alpha=1.0)
meta.fit(stack_features, y)
stack_pred = meta.predict(stack_features)
print('Stacked (train) MCRMSE:', mcrmse(y, stack_pred)[0])

# Evaluate per-target RMSE for each model type
for name, preds in [('PLS', oof_pls), ('LGB', oof_lgb), ('Hybrid', oof_hybrid), ('Stack', stack_pred)]:
    mcrm, per_rmse = mcrmse(y, preds)
    print(f'{name}: MCRMSE={mcrm:.5f} | per-target RMSE: {dict(zip(TARGETS, np.round(per_rmse,4)))}')

# Plot predicted vs actual for each target (stack)
import matplotlib.pyplot as plt
fig, axs = plt.subplots(2,3, figsize=(15,8))
axs = axs.flatten()
for i, t in enumerate(TARGETS):
    axs[i].scatter(y[:,i], stack_pred[:,i], alpha=0.5, s=8)
    axs[i].plot([y[:,i].min(), y[:,i].max()],[y[:,i].min(), y[:,i].max()], 'r--')
    axs[i].set_title(t)
plt.tight_layout()
plt.show()